{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlochub/MIT-Xpro-colab/blob/main/SoftImpute_for_Movielens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3c46e94",
      "metadata": {
        "id": "b3c46e94"
      },
      "source": [
        "#  The MovieLens Dataset\n",
        "\n",
        "[MovieLens](https://movielens.org/) is a non-commercial web-based movie recommender system, created in 1997 by GroupLens, a research lab at the University of Minnesota, in order to gather movie rating data for research purposes.\n",
        "\n",
        "\n",
        "## Getting the Data\n",
        "\n",
        "\n",
        "The MovieLens dataset is hosted by the [GroupLens](https://grouplens.org/datasets/movielens/) website. Several versions are available. We will use the latest smallest dataset released from [link](https://files.grouplens.org/datasets/movielens/ml-latest-small.zip).\n",
        "\n",
        "## Custom Code\n",
        "\n",
        "The custom packages; soft_impute and functionsCF will need to be installed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the standard papackages\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install fancyimpute"
      ],
      "metadata": {
        "id": "f5x_KMp8fpxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976b7550-0396-4239-e955-626dd10dabff"
      },
      "id": "f5x_KMp8fpxo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting fancyimpute\n",
            "  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting knnimpute>=0.1.0 (from fancyimpute)\n",
            "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from fancyimpute) (1.6.1)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.11/dist-packages (from fancyimpute) (1.6.6)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.11/dist-packages (from fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from fancyimpute) (8.3.5)\n",
            "Collecting nose (from fancyimpute)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.11/dist-packages (from knnimpute>=0.1.0->fancyimpute) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (3.6.0)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from cvxpy->fancyimpute) (1.0.4)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy->fancyimpute) (0.11.1)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/dist-packages (from cvxpy->fancyimpute) (3.2.7.post2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->fancyimpute) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytest->fancyimpute) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->fancyimpute) (1.6.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.11/dist-packages (from clarabel>=0.5.0->cvxpy->fancyimpute) (1.17.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy->fancyimpute) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy->fancyimpute) (75.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi->clarabel>=0.5.0->cvxpy->fancyimpute) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->osqp>=0.6.2->cvxpy->fancyimpute) (3.0.2)\n",
            "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fancyimpute, knnimpute\n",
            "  Building wheel for fancyimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29879 sha256=f3c1cca4b67ecc8120416d3dc6bf20c72a13a2c46411a801390561ce8f58bf65\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/f3/a1/f7f10b5ae2c2459398762a3fcf4ac18c325311c7e3163d5a15\n",
            "  Building wheel for knnimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11331 sha256=37d457a58445d677ae45feb68f8d0849434df7f6ae18de452998293bc136b715\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e8/e0/79872972161e54486517ae507f94b2c7cea27fb7ef793bd415\n",
            "Successfully built fancyimpute knnimpute\n",
            "Installing collected packages: nose, knnimpute, fancyimpute\n",
            "Successfully installed fancyimpute-0.7.0 knnimpute-0.1.0 nose-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Collab Connection to Google Drive: External data: Local Files, Drive, Sheets, and Cloud Storage\n",
        "https://colab.research.google.com/notebooks/io.ipynb"
      ],
      "metadata": {
        "id": "cA4Pv9fGpe19"
      },
      "id": "cA4Pv9fGpe19"
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "AFNnBYR2hAEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d969921a-93ea-4e99-c089-255837d5987c"
      },
      "id": "AFNnBYR2hAEB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# location of custom packages: soft_impute , functionsCF, and dataset ratings.csv\n",
        "# CollaborativeFiltering folder in google drive\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/CollaborativeFiltering/')"
      ],
      "metadata": {
        "id": "IsIo2LkxhhQl"
      },
      "id": "IsIo2LkxhhQl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change the working directory\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/CollaborativeFiltering/\")"
      ],
      "metadata": {
        "id": "qv7OvJ8nr0TU"
      },
      "id": "qv7OvJ8nr0TU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ae0c8f",
      "metadata": {
        "id": "e8ae0c8f"
      },
      "outputs": [],
      "source": [
        "# Impute necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from fancyimpute import BiScaler\n",
        "from soft_impute import SoftImpute\n",
        "from functionsCF import GenerateTrainingSet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40bbbdd4",
      "metadata": {
        "id": "40bbbdd4"
      },
      "source": [
        "## Create the incomplete matrices for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read movielens data from files- point to where data is stored, small set of Movielens dataset\n",
        "# 100836 (rows), userId\tmovieId\trating\ttimestamp (columns).\n",
        "# Using smaller dataset rather than the full dataset to speed performance.\n",
        "# Your results may vary depending on which Movielens data set is used; Several are available online\n",
        "# read in values only\n",
        "rating = pd.read_csv('ratings.csv', sep=',').values"
      ],
      "metadata": {
        "id": "Vsbz4zO0j7DB"
      },
      "id": "Vsbz4zO0j7DB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we only care about the ratings, so we only use the first three columns, which contain use IDs, movie IDs, and ratings.\n",
        "rating = rating[:,0:3]"
      ],
      "metadata": {
        "id": "ptTHCfTfxBuC"
      },
      "id": "ptTHCfTfxBuC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show top 5 rows\n",
        "print(rating[:5, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-i471csu_K3",
        "outputId": "86e2dc6d-dd11-47c8-8dd8-d75238dae057"
      },
      "id": "a-i471csu_K3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.  1.  4.]\n",
            " [ 1.  3.  4.]\n",
            " [ 1.  6.  4.]\n",
            " [ 1. 47.  5.]\n",
            " [ 1. 50.  5.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23d947b",
      "metadata": {
        "id": "b23d947b"
      },
      "outputs": [],
      "source": [
        "# Use all known information to create the incomplete matrix\n",
        "\n",
        "# First, create an empty matrix\n",
        "matrix_incomplete = np.zeros((len(np.unique(rating[:,0])), len(np.unique(rating[:,1]))))\n",
        "\n",
        "# Second, Since some movies don't have any ratings, we only use the movies that have ratings.\n",
        "# Here we correspondingly change the movie IDs to make each column has ratings.\n",
        "# create an array of all movie IDs\n",
        "usedID = np.unique(rating[:, 1])\n",
        "# replace the movie IDs by the their positions in the array we just created\n",
        "for i in range(len(rating[:,1])):\n",
        "    rating[:,1][i] = np.where(usedID==rating[:,1][i])[0][0] + 1\n",
        "\n",
        "# Finally, we construct the incomplete matrix, on which the incomplete components are nan by\n",
        "# default.\n",
        "# all components are nan by default\n",
        "matrix_incomplete[:] = np.nan\n",
        "# create the index pair of the components with ratings\n",
        "indices = np.array(rating[:,0] - 1).astype(int), np.array(rating[:,1] - 1).astype(int)\n",
        "# change the values in the corresponding positions to the known rating information\n",
        "matrix_incomplete[indices] = rating[:,2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f54b0e6",
      "metadata": {
        "id": "2f54b0e6"
      },
      "outputs": [],
      "source": [
        "# Obtain the index pairs of the training set and the validation set, with ratio 90%\n",
        "train_indices, validation_indices = GenerateTrainingSet(rating[:,0], rating[:,1], 0.90)\n",
        "# And then use the index pairs to create the incomplete training test\n",
        "matrix_train = matrix_incomplete.copy()\n",
        "matrix_train[:] = np.nan\n",
        "matrix_train[train_indices] = matrix_incomplete[train_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69a998c9",
      "metadata": {
        "id": "69a998c9"
      },
      "source": [
        "##  Run the softImpute model for collaborative filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d16d1db",
      "metadata": {
        "id": "0d16d1db"
      },
      "outputs": [],
      "source": [
        "# Create the BiScaler model\n",
        "biscaler = BiScaler(scale_rows=False, scale_columns=False, max_iters=50, verbose=False)\n",
        "# Rescale both rows and columns to have zero mean\n",
        "matrix_train_normalized = biscaler.fit_transform(matrix_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae5de031",
      "metadata": {
        "id": "ae5de031"
      },
      "outputs": [],
      "source": [
        "# Use softImpute to complete the matrix. J means the number of archetypes and rand_seed means the\n",
        "# seed for the inner random number generator, verbose control whether outputting algorithm logs.\n",
        "softImpute = SoftImpute(J = 4, maxit = 200, random_seed = 1, verbose = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19484161",
      "metadata": {
        "id": "19484161"
      },
      "outputs": [],
      "source": [
        "# Run the softImpute model on the normalized training set\n",
        "matrix_train_softImpute = softImpute.fit(matrix_train_normalized)\n",
        "# Use the softImpute model to create the predicted matrix. If we set copyto as True, then it\n",
        "# directly change the value of matrix_train_normalized\n",
        "matrix_train_filled_normalized = matrix_train_softImpute.predict(matrix_train_normalized, copyto = False)\n",
        "# Inverse transformation to undo the scaling\n",
        "matrix_train_filled = biscaler.inverse_transform(matrix_train_filled_normalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9481eb67",
      "metadata": {
        "id": "9481eb67"
      },
      "source": [
        "## Analysis of the predicted ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "988d616f",
      "metadata": {
        "id": "988d616f"
      },
      "source": [
        "### Out-of-sample R^2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a097cfe2",
      "metadata": {
        "id": "a097cfe2"
      },
      "outputs": [],
      "source": [
        "# Create the baseline method\n",
        "train_average = np.average(matrix_train[train_indices])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d89639dd",
      "metadata": {
        "id": "d89639dd",
        "outputId": "fbd174ee-a07a-4411-e5eb-32caa1b991d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out-of-sample R2: 0.1968, in-sample R2: 0.6343.\n"
          ]
        }
      ],
      "source": [
        "# Calculate out-of-sample R2 and in-sample R2\n",
        "# Your results may vary from the lesson due to datasize and training test split.\n",
        "validation_mse = ((matrix_train_filled[validation_indices] - matrix_incomplete[validation_indices]) ** 2).mean()\n",
        "training_mse = ((matrix_train_filled[train_indices] - matrix_incomplete[train_indices]) ** 2).mean()\n",
        "validation_mse_baseline = ((train_average - matrix_incomplete[validation_indices]) ** 2).mean()\n",
        "training_mse_baseline = ((train_average - matrix_incomplete[train_indices]) ** 2).mean()\n",
        "print(\"out-of-sample R2: %.4f, in-sample R2: %.4f.\" % (1 - validation_mse / validation_mse_baseline, 1 - training_mse / training_mse_baseline))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d09890c5",
      "metadata": {
        "id": "d09890c5"
      },
      "source": [
        "### Get low-rank factors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78125afd",
      "metadata": {
        "id": "78125afd",
        "outputId": "e285588e-68b0-4514-ccff-efc3711f5e97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.00120371, -0.0126243 , -0.01569624, -0.00489712],\n",
              "       [-0.00588053, -0.00410622, -0.00701788, -0.00271441],\n",
              "       [-0.00560296,  0.00767393, -0.00861866,  0.01191865],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Obtain the ratings of each archetype\n",
        "# Each row of this matrix corresponds to a song and each column corresponds to an archetype\n",
        "softImpute.v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c37024e",
      "metadata": {
        "id": "1c37024e",
        "outputId": "b812542a-90f6-487a-c5c8-4692ebf12c2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9724, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "softImpute.v.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6250e638",
      "metadata": {
        "id": "6250e638",
        "outputId": "d04b9015-0a39-47c1-87d9-5366d27965f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -9.55732307,  -8.14603301,   8.80230765,   4.76432235],\n",
              "       [-14.24049083,  -6.06898543,  -0.34951558,   5.47545152],\n",
              "       [-60.13264768, -19.48473727,  57.0010829 ,  36.11188168],\n",
              "       ...,\n",
              "       [  0.7833923 ,  52.01879593,  25.71779472, -12.0670246 ],\n",
              "       [ -6.24094062,  -0.68394357,   4.12038907,  -2.18463982],\n",
              "       [  7.4236412 , -22.0291323 ,  -0.41552704,  13.79213509]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# (Optional)\n",
        "# Obtain the weights of archetypes of each user\n",
        "# each row of this matrix corresponds to a user and each column corresponds to an archetype\n",
        "weights = np.dot(softImpute.u, np.diagflat(softImpute.d).T)\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3dd121c",
      "metadata": {
        "id": "c3dd121c",
        "outputId": "a01c6498-97c4-45a7-d382-803394d70c72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(610, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf2f7437",
      "metadata": {
        "id": "cf2f7437"
      },
      "outputs": [],
      "source": [
        "# And then the predicted matrix is computed by the product of two low-rank matrices\n",
        "new_prediction = np.dot(weights, softImpute.v.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7421f9c",
      "metadata": {
        "id": "d7421f9c",
        "outputId": "b70e92aa-71fd-4a07-eaf3-2b106b9c48c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(7.909104785166668e-11)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# We can see it is the same with the output of the codes in the previous section\n",
        "np.sum(np.abs(new_prediction - matrix_train_filled_normalized))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0831b6a",
      "metadata": {
        "id": "c0831b6a"
      },
      "source": [
        "end of the note"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}